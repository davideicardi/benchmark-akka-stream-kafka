sampleTopic = "topicSample"
recordBodyFile = "./recordBodyFile.bin"
numberOfKeys = 100

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "INFO"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
}

# https://doc.akka.io/docs/akka-stream-kafka/current/producer.html#settings
# Properties for akka.kafka.ProducerSettings can be
# defined in this section or a configuration section with
# the same layout.
akka.kafka.producer {
  # Tuning parameter of how many sends that can run in parallel. (we override this, see streaming.parallelism)
  parallelism = 100

  # How long to wait for `KafkaProducer.close`
  close-timeout = 60s

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the producer stages. Some blocking may occur.
  # When this value is empty, the dispatcher configured for the stream
  # will be used.
  # use-dispatcher = "akka.kafka.default-dispatcher"

  # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
  eos-commit-interval = 100ms

  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
  # can be defined in this configuration section.
  #  https://kafka.apache.org/documentation/#producerconfigs
  kafka-clients {
    bootstrap.servers = "localhost:9092"
    enable.idempotence = true # Idempotence is required to achieve "Exactly Once" Semantic.
    batch.size = 2097152 # 2 MB attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition.
    max.request.size = 2097152
    linger.ms = 5 # sets the maximum time to buffer data in asynchronous mode, increase to increase throughput and latency
    acks = "all" # Producer will receive a success response from the broker once all in-sync replicas received the message
    retries = 30 # Max number of times the producer will retry sending the message before giving up and notifying the client of an issue
    max.in.flight.requests.per.connection = 1 # The maximum number of unacknowledged requests the client will send on a single connection before blocking.
    compression.type = "lz4"
    client.id = "sample-producer-1"

    # Enable kerberos auth
    # security.protocol = "SASL_SSL"
    # sasl.kerberos.service.name = "kafka"
  }
}
